# @package _group_
name: a2c
num_envs: 8
num_steps: 10
device: ${device}
network_params:
  architecture: "rnn"
  state_channels: 32
  hidden_size: 64
  random_cog_fraction: 0.0
  fixed_recursive_depth: 1
  append_a_cog: true
  append_coords: false
  pool_and_inject: false
  detach_cognition: true
  skip_connection: false
  two_transitions: false
algo_params:
  twoAM: false
  cognitive_coef: 1.0
  cognitive_cost: 0.1
  cognitive_rewards: AD
  lr: 1e-3
  gamma: 0.99
  gamma_cog: 0.99
  value_loss_coef: 0.5
  entropy_coef: 0.01
  eps: 1e-5
  alpha: 0.99
  max_grad_norm: 0.2
  use_timeout: true
  smooth_value_loss: true
  reward_rescale: ${env.reward_rescale}
  update_cognitive_values: false
  optimizer_type: rmsprop
