# @package _group_
name: a2c
num_envs: 128
num_steps: 10
device: ${device}
network_params:
  architecture: "rnn"
  state_channels: 64
  hidden_size: 512
  random_cog_fraction: 0.0
  fixed_recursive_depth: 3
  append_a_cog: false
  append_coords: true
  pool_and_inject: false
  detach_cognition: true
  skip_connection: false
  two_transitions: false
algo_params:
  twoAM: false
  cognitive_coef: 0.99
  cognitive_cost: 0.1
  cognitive_rewards: AC
  lr: 7e-4
  gamma: 0.99
  gamma_cog: 0.9
  value_loss_coef: 0.5
  entropy_coef: 0.01
  eps: 1e-5
  alpha: 0.99
  max_grad_norm: 0.1
  use_timeout: true
  smooth_value_loss: false
  reward_rescale: ${env.reward_rescale}
  update_cognitive_values: true
  optimizer_type: rmsprop
