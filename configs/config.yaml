num_timesteps: ${env.num_timesteps}
device: cuda:0
seed: 0
num_envs: ${agent.num_envs}
model_params_count: ???
name: any

log_timestep_interval: 1e3
log_save_tb: true
save_video: true
eval_timestep_interval: 1e5
num_eval_episodes: 32
num_eval_envs: ${env.num_eval_envs}

defaults:
  - env: atari
#  - env: minipacman
#  - env: mazelab
#  - env: cartpole
#  - env: frozenlake
#  - env: lunarlander
#  - env: mg
  - env: pc
#  - env: minatar
#  - env: snake
#  - env: tetris
  - agent: a2c_image
#  - agent: a2c_game
#  - agent: a2c_proprio
#  - hydra/sweeper: nevergrad


# hydra configuration
hydra:
  run:
    dir: ./runs/${now:%Y.%m.%d}/${now:%H%M%S}_${name}
  sweep:
    dir: ./multirun/${now:%Y-%m-%d}/${name}_${now:%H-%M-%S}
    subdir: ${name}_${hydra.job.num}
#  sweeper:
#    params:
#      optim:
#        optimizer: OnePlusOne
#        # total number of function evaluations to perform
#        budget: 20
#        # number of parallel workers for performing function evaluations
#        num_workers: 1
#        maximize: true