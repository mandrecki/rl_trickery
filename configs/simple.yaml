num_timesteps: 1e6
device: cuda:0
seed: 0
num_envs: ${agent.num_envs}
model_params_count: ???

log_timestep_interval: 1e3
log_save_tb: true
save_video: true
eval_timestep_interval: 1e5
num_eval_episodes: 32

defaults:
#  - env: atari
#  - env: mazelab
#  - env: cartpole
  - env: frozenlake
#  - env: lunarlander
#  - env: pixelcopter
#  - env: tetris
  - agent: a2c_image
#  - agent: a2c_proprio
#  - hydra/sweeper: nevergrad


# hydra configuration
hydra:
  run:
    dir: ./runs/${now:%Y.%m.%d}/${now:%H%M%S}_${hydra.job.override_dirname}
  sweep:
    dir: ./multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
#  sweeper:
#    params:
#      optim:
#        optimizer: OnePlusOne
#        # total number of function evaluations to perform
#        budget: 20
#        # number of parallel workers for performing function evaluations
#        num_workers: 1
#        maximize: true